> 一、论文阅读  
二、关于混合缩放方向  
三、工作安排
# 一、论文阅读

<br/>

## 1、资源受限、多租户无服务器计算环境中应用程序调度的深度强化学习
<br/>

- 该文需要解决的问题

        总结：大多数现有的无服务器调度工作都提供函数调度的启发式技术，这些技术无法捕捉到这些系统中由多租户和不同的用户请求模式引起的真正动态。此外，他们很少考虑实现提供商资源效率和应用程序性能这两个经常相互矛盾的双重目标。

        存在的问题：现有的商业无服务器平台在功能调度方面大多遵循简单的启发式方法。AWS Lambda将函数放置决策视为最大化 VM 内存利用率的装箱问题。 Azure Functions 遵循分散放置策略，以避免同一VM上同一功能的并发实例共置。IBM OpenWhisk采用基于哈希的首次适配启发式算法，旨在提高缓存命中率和实例​​重用。在研究文献中，许多人都尝试介绍函数调度技术。大多数现有工作主要集中在满足用户的应用程序延迟要求和管理最终用户的资源成本，而不是优化云提供商基础设施成本。此外，他们的努力主要针对针对单个请求调度的更简单问题阐明启发式解决方案，基于每个功能实例仅服务于单个并发请求的系统模型。许多工作也未能获得整体工作负载和系统感知，这不利于在高度动态的无服务器系统中提供的解决方案的有效性。

        该文提供的方法的优点：该文解决了调度功能实例的复杂问题，这些实例为多个并发请求提供服务，以一种具有成本效益的方式，完全了解工作负载模式和系统动态，因此应用程序性能不会因资源争用而受到阻碍。


- 解决方案

        该文提出了一种结合深度强化学习 (DRL) 的新技术，以克服上述在具有异构计算资源的高度动态无服务器计算环境中进行函数调度的挑战。该文在结合 Kubeless 的实际环境中训练和评估模型。

        现有的文献中对一般的云调度问题基本都是在仿真环境中进行的模拟实验，该文设计的实际测试平台进行训练和实验，并且实验结果相较于其他的baseline实验。主要贡献如下：
        1、该文在资源受限的多租户无服务器计算环境中，为功能实例调度问题建立了一个面向RL的模型。
        2、该文提出了一个多步骤深度Q学习（DQN）模型，用于为无服务器功能开发工作负载和系统感知调度框架，旨在优化应用程序响应时间延迟和提供商成本效率。由于这两个目标相互冲突，该文为模型增加了灵活性，以根据用户的需要在这些目标之间建立平衡。
        3、该文为DRL代理设计了一个实用的培训环境，与开源无服务器平台Kubeless集成，该平台部署在由异构VM组成的Kubernetes集群上。
        4、该文使用真实世界中的单个和多功能无服务器应用程序和从Microsoft Azure Functions中捕获的功能跟踪进行了广泛的实验，以评估所提出的DRL模型的性能和可扩展性，并将其与基线调度器进行比较。





- 实验

        通过在Kubernetes集群上使用无服务器框架Kubeless设计和实现一个实验框架，主要由一个控制集群、一个工作集群和与控制集群通信的DRL代理组成。

<div align=center><image src="../Markdown图片/23-2-26系统架构.jpg" height="500" ></div>
<p align=center>图1 用于训练和评估DRL代理的实用测试平台的系统结构</p>
<div align=center><image src="../Markdown图片/23-2-26通信流程.jpg" height="300" ></div>
<p align=center>图2 训练阶段DRL代理与集群的通信流程</p>


- 结论

        比较大的篇幅讲解了在实验中使用到的方法和与他的对比实验进行的对比。性能指标主要有以下几点：相对应用程序响应时间比、平均节点数、虚拟机使用成本、吞吐量。并在应用程序响应时间和资源成本效率两个优化目标下，讨论了提出的模型与基线算法的性能比较。讨论了应用程序响应时间性能与RART比率和系统吞吐量的关系。
        Baselines schedulers分别有：Round Robin (RR)、Bin packing First-Fit (BPFF)、Static Time Cost Aware (STCA)、Dynamic Time Cost Aware (DTCA)、LZ-based、KC。
        
        应用程序性能：
        在10VM集群中，该文的DQN (β = 0)模型在响应时间方面表现最差，因为agent被训练成完全专注于提高资源成本效率，从而在很大程度上妥协于应用程序性能。BPFF和STCAH算法在响应时间方面也表现出较差的性能，STCA-H算法的系统吞吐量仅次于DQN (β = 0)，这两种方法都倾向于将新的功能实例放在最拥挤的虚拟机上，导致对节点资源的竞争加剧。RR算法的性能相对较好，因为每个连续的函数实例都分布在集群虚拟机中。但由于这只会导致在不了解具体功能或系统特征的情况下，在节点之间随机平衡负载，因此所获得的结果是次优的。KC的性能与RR相似。STCA-L算法根据系统的静态参数进行调度决策。虽然这种方法的决策结果相对较好，但由于这种方法对复杂的系统能动没有全面的了解，因此在寻找最优解时缺乏竞争力。
        在20VM集群中，在请求率的最高水平上，DQN (β = 1)模型表明RFRT比STCAL提高了20%。在此场景下，其他基线调度算法的响应时间行为与20-40负载级别的响应时间行为基本相似。
        资源使用效率：
        在10VM集群中，DQN (β = 0)模型与STCA-H和BPFF这两种性能次之的非drl技术相比，虚拟机使用成本分别降低了11%和15%。其中DQN的平均使用的虚拟机数量(β = 0)是最低的。STCA-L算法的虚拟机使用成本最高，平均使用节点数也排名靠前，这反映了最差的性能。因为其策略是通过系统参数确定运行功能最少、资源利用率最低的高容量节点，用于功能调度。这导致更多的集群节点经常大大低于其容量。其次是RR、KC和DQN (β = 1)算法。
        在20VM集群中，请求率在5-20之间，DQN (β = 0)模型显示虚拟机使用成本降低了34%，优于基线算法BPFF。与BPFF相比，STCA-H、lz和DTCA算法的VM开销略高。请求率在20-40之间时，DQN (β = 0)与BPFF、STCA-H和基于lz的基准算法相比，仍然实现了最佳性能，虚拟机成本降低了25%。在最高的40-60之间，有着更好的资源使用率，DQN (β = 0.25)模型优于仅关注成本改进的DQN (β = 0)代理。这也证明，在节点资源的高压力下（也就是在资源受限的情况下），将这两个目标都考虑在内会导致训练出一个从长远来看更有效地优化成本的策略。BPFF和STCA-H算法的性能相对较差，它们通常擅长打包函数实例以节省成本，这也说明了在重载集群中应用程序性能对成本性能的潜在间接影响。此外，与BPFF和STCA-H等基线相比，DQN (β = 0)和DQN (β = 0.25)代理在使用中的平均虚拟机数量上仅显示出边际差异。这进一步证实了这样一个事实，即在高负载水平下，所实现的成本效率主要是由于将不同的应用程序实例智能地放置在合适的低成本主机节点上，因为简单地将它们打包到更少的vm上只能有限地提高成本。

        实验结果表明，在高负载水平下，所实现的成本效率主要是由于将不同的应用程序实例智能地放置在合适的低成本主机节点上，因为简单地将它们打包到更少的vm上只能有限地提高成本。

        
<div align=center><image src="../Markdown图片/23-2-2610Vm.jpg" height="200" ></div>
<p align=center>图3 在10个VM集群中，通过DRL模型和基线算法比较RART比率、吞吐量、总VM成本和系统中使用的平均节点数。</p>
<div align=center><image src="../Markdown图片/23-2-2620Vm.jpg" height="450" ></div>
<p align=center>图4 在20个VM集群中，通过DRL模型和基线算法比较RART比率、吞吐量、总VM成本和系统中使用的平均节点数。</p>
<br/>

- 总结 

        无服务器计算模型为云提供商和最终用户的资源管理提供了灵活性。但是，由于资源限制，当应用程序需求级别随着时间快速变化时，这些计算环境的多租户特性可能会导致功能性能的复杂变化

<br/>




# 二、关于混合缩放方向  
>HPA是增加或减少pod的数量，而VPA是根据计算资源(如CPU和内存)改变pod的大小。

        基于现有阅读的文献内容，大概列举了研究方向及研究方法有如下几种：
        1、将混合缩放的典型文章COPA方法，对排队网络模型M/M/c模型进行深入研究或替换为更优的算法，后根据实时工作量和期望响应时间等指标，确定HPA和VPA的最优解应用在自动缩放中。（但是在一些文章中介绍，HPA和VPA不能同时运行，文中写的是“强烈建议在Kubernetes中一次只选择一种类型的自动缩放模式，以避免其他人在使用相同类型的度量时受到干扰。”）--《COPA: Combined Autoscaling Method for Kubernetes》--2021 IEEE International Conference on Web Services (ICWS)；
        2、应用论文中HPA+的方法（对比多种学习模型，各种机器学习预测方法通过短期评估循环相互竞争，选择最适合实际请求动态的方法），将VPA以同样的方式进行预测竞争，可以类比HPA+做VPA+。还没有看到有类似的文章，可行性有待确定，还有就是该方法的实验难度可能会比较高。--《 Machine Learning-Based Scaling Management for Kubernetes Edge Clusters》--IEEE Transactions on Network and Service Management(IEEE TNSM)；
        3、同HPA+方法，将VPA与HPA进行比较......；
现在的难题主要是：   
1、对想到的方向实现起来具体难度的评估不知道怎么进行。  
2、没有了解k8s中各方法的具体运行流程，比如HPA和VPA是否可以同时运行之类的这些问题。所以有时候想到一个idea但是因为不了解所以无法详细写下idea的思路。

<br/><br/>

# 三、工作安排
1、阅读相关文献（关于HPA和VPA同时运行的相关文献，是否有其他可实现办法）： 
 ```
[11] D. Balla, C. Simon, and M. Maliosz, ‘‘Adaptive scaling of kubernetes
pods,’’ in Proc. IEEE/IFIP Netw. Oper . Manag. Symp., Apr. 2020, pp. 1–5.  

[12] L. Baresi, D. Hu, G. Quattrocchi, and L. Terracciano, ‘‘KOSMOS: V ertical
and horizontal resource autoscaling for kubernetes,’’ in Proc. Int. Conf.
Service-Oriented Comput. (ICSOC), 2021, pp. 821–829.  
```
2、开始了解k8s中HPA和VPA的代码、实验相关内容，对idea的详细思路进行总结。  
3、找①关于资源受限或冷启动相关文献，②HPA和VPA混合缩放文献，③深度强化学习、启发式算法相关文献，然后找到适合的算法或环境条件明确方向。